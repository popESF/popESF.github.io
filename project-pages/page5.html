<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The York Declaration: An Ethical Approach for LLM Deployment</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      line-height: 1.6;
      color: #333;
      margin: 0;
      padding: 0;
    }
    header, footer {
      background-color: #2E3B4E;
      color: white;
      text-align: center;
      padding: 20px;
    }
    header h1, footer p {
      margin: 0;
    }
    .container {
      max-width: 800px;
      margin: 20px auto;
      padding: 0 15px;
    }
    h2, h3 {
      color: #2E3B4E;
    }
    p {
      margin-bottom: 15px;
    }
    ul {
      margin: 15px 0;
      padding-left: 20px;
    }
    .maxims-list {
      padding: 0;
      list-style: none;
      margin: 0;
    }
    .maxims-list li {
      margin-bottom: 20px;
    }
    .recommendations {
      background-color: #f9f9f9;
      padding: 15px;
      border-left: 4px solid #2E3B4E;
    }
  </style>
</head>
<body>
  <header>
    <h1>The York Declaration: An Ethical Approach for LLM Deployment</h1>
  </header>
  <div class="container">
    <p><strong>UKRI AI Centre for Doctoral Training in Safe Artificial Intelligence Systems (SAINTS)</strong> in York, UK has aimed to bridge the gap between disciplines by bringing together doctoral scholars from various fields. These scholars have united to consider ethical issues arising from AI, particularly focusing on large language models (LLMs) due to their unique capabilities. This declaration aims to protect end users by addressing ethical concerns at the point of deployment, ensuring a responsible future for LLM systems.</p>

    <h2>Preamble</h2>
    <p>Radical transformations necessitate radical challenges that must be anticipated and addressed. We, as responsible members of society and future scientists, ask fundamental questions: What should AI not do? What rules should guide its deployment? While this is a topic for democratic debate, common sense morality suggests technology should not lie, alienate, dominate, or discriminate. Our goal is a society that fosters human autonomy and harmony with the environment.</p>

    <h2>The 7 York Maxims</h2>
    <p>Our conclusions, drawing from sources such as the Alan Turing Institute and UNESCO, are expressed through the following seven maxims:</p>
    <ul class="maxims-list">
      <li><strong>“Do no harm”: Safe Systems</strong> - Safety is defined as the absence of unintentional harm, while security is the absence of intentional harm. Addressing these risks requires a multi-disciplinary approach involving safety engineering, machine learning, sociology, and philosophy.</li>
      <li><strong>Aim for neutrality, when not justice</strong> - LLM deployment should aim to avoid bias and ensure fair treatment across diverse groups, focusing on equitable outcomes to prevent discrimination.</li>
      <li><strong>Tackling transparency</strong> - Transparency concerns the availability of information about an LLM, including responsible actors and limitations. We recommend third-party audits to ensure accountability without revealing sensitive trade secrets.</li>
      <li><strong>Moral responsibility: shifting accountability space</strong> - Developers hold increasing responsibility as LLMs gain agency. Shifting liability patterns require rigorous testing and risk mitigation.</li>
      <li><strong>Preserving the only ecosystem fit for life</strong> - To mitigate LLMs' environmental impact, deployment should align with sustainability goals, minimizing emissions and resource usage.</li>
      <li><strong>Anticipating the mutations of employment</strong> - To counter potential job displacement, we recommend exploring reskilling, Universal Basic Income, and shared productivity gains.</li>
      <li><strong>Windows for agency on both individual and collective levels</strong> - AI systems must respect autonomy and avoid creating a surveillance society. Third-party evaluations should guard against misinformation and maintain democratic principles.</li>
    </ul>

    <h3>Recommendations:</h3>
    <div class="recommendations">
      <ul>
        <li>Ensure data integrity to avoid replicating societal biases.</li>
        <li>Promote equitable access to technology, avoiding alienation of certain groups.</li>
        <li>Implement third-party audits and adversarial testing to maintain transparency and accountability.</li>
      </ul>
    </div>

    <h2>Conclusion</h2>
    <p>The York Declaration provides a practical, ethical framework for LLM deployment. Grounded in a commitment to fairness, transparency, accountability, sustainability, and safety, this declaration offers a path toward responsible innovation, balancing technological advancement with robust safeguards to protect human autonomy, privacy, and social equity in an AI-integrated world.</p>
  </div>
  <footer>
    <p>&copy; 2024 UKRI AI Centre for Doctoral Training in Safe Artificial Intelligence Systems (SAINTS), York, UK</p>
  </footer>
</body>
</html>
